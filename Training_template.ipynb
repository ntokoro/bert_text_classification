{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torch transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import section\n",
    "import time, datetime, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import(\n",
    "    DataLoader,\n",
    "    RandomSampler,\n",
    "    SequentialSampler,\n",
    "    TensorDataset,\n",
    "    random_split\n",
    ")\n",
    "import transformers\n",
    "from transformers import(\n",
    "    AutoTokenizer,\n",
    "    RobertaForSequenceClassification, # Import the model of your choice\n",
    "    get_linear_schedule_with_warmup,\n",
    "    AdamW\n",
    ")\n",
    "from nltk.metrics import ConfusionMatrix # Looks better than the sklearn CM\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition section\n",
    "\n",
    "wc = 200 # number of words for submission truncation\n",
    "seed_val = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_stat(predictions, actual) :\n",
    "    #Flatten predictions array\n",
    "    preds = [np.argmax(subarr) for arr in predictions for subarr in arr]\n",
    "    true_labels_1d = []\n",
    "\n",
    "    #Flatten true_labels array\n",
    "    for arr in actual:\n",
    "        true_labels_1d.extend(arr.tolist())\n",
    "\n",
    "    #Print confusion matrixs and measures\n",
    "    cm = ConfusionMatrix(true_labels_1d, preds)\n",
    "    class_rep = classification_report(true_labels_1d, preds)\n",
    "    print(cm)\n",
    "    print(class_rep)\n",
    "    return(preds, true_labels_1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all of the sentences and map the tokens to their word IDs.\n",
    "# max_len was set at 355 because the max token count for 200 words was 355 in the sample\n",
    "# Max is 512 if using BERT-based models, higher for longformer (2000+)\n",
    "def toke_and_enc(sentences, max_len=355):\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "    for sent in sentences:\n",
    "        encoded_dict = tokenizer.encode_plus(\n",
    "                            sent,\n",
    "                            add_special_tokens = True,\n",
    "                            max_length = max_len,\n",
    "                            pad_to_max_length = True,\n",
    "                            return_attention_mask = True,\n",
    "                            return_tensors = 'pt',\n",
    "                            truncation = True\n",
    "                       )\n",
    "        \n",
    "        input_ids.append(encoded_dict['input_ids'])\n",
    "        attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "    input_ids = torch.cat(input_ids, dim=0)\n",
    "    attention_masks = torch.cat(attention_masks, dim=0)\n",
    "    \n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(train_dataset, batch_size=16) :\n",
    "    \n",
    "    train_dataloader = DataLoader(\n",
    "            train_dataset,\n",
    "            sampler = RandomSampler(train_dataset),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "    return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataset) : \n",
    "    train_dataloader = create_data_loader(train_dataset)\n",
    "\n",
    "    #Change the model name and num_labels depending on the task.\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels = 10)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5,\n",
    "                  eps = 1e-8\n",
    "                )\n",
    "    \n",
    "    epochs = 10 # Change if needed\n",
    "\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = total_steps)\n",
    "\n",
    "    random.seed(seed_val)\n",
    "    np.random.seed(seed_val)\n",
    "    torch.manual_seed(seed_val)\n",
    "\n",
    "\n",
    "    for epoch_i in range(0, epochs):\n",
    "\n",
    "        print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "        total_train_loss = 0\n",
    "   \n",
    "        model.train()\n",
    "        print(\"here\")\n",
    "\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            print('.', end =\"\")\n",
    "            b_input_ids = batch[0]\n",
    "            b_input_mask = batch[1]\n",
    "            b_labels = batch[2]\n",
    "\n",
    "            model.zero_grad()        \n",
    "\n",
    "            loss, logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask,  labels=b_labels)\n",
    "\n",
    "            total_train_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "        print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(test_dataset, model) : \n",
    "    \n",
    "    test_sampler = SequentialSampler(test_dataset)\n",
    "\n",
    "    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=16)\n",
    "   \n",
    "    print('here')\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    predictions , true_labels = [], []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        print(\".\", end =\" \")\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "        with torch.no_grad():\n",
    "              outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs[0]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "        predictions.append(logits)\n",
    "        true_labels.append(label_ids)\n",
    "\n",
    "    print('DONE.')\n",
    "    return(predictions, true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  559 training samples\n",
      "  140 test samples\n",
      "======== Epoch 1 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 1.97\n",
      "======== Epoch 2 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 1.54\n",
      "======== Epoch 3 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 1.25\n",
      "======== Epoch 4 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 1.04\n",
      "======== Epoch 5 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.82\n",
      "======== Epoch 6 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.66\n",
      "======== Epoch 7 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.54\n",
      "======== Epoch 8 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.45\n",
      "======== Epoch 9 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.38\n",
      "======== Epoch 10 / 10 ========\n",
      "here\n",
      "...................................  Average training loss: 0.35\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "pathtofile = './data/sample2018prep_3.csv' # The data; tsv also ok\n",
    "df = pd.read_csv(pathtofile, encoding='utf-8')\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "dftrain=df.sample(frac=0.8,random_state=seed_val)\n",
    "dftest=df.drop(dftrain.index)\n",
    "print('{:>5,} training samples'.format(len(dftrain)))\n",
    "print('{:>5,} test samples'.format(len(dftest)))\n",
    "\n",
    "# set tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('roberta-base') #Change this if using a different model\n",
    "\n",
    "# construct the input for the training phase\n",
    "All_text_train = dftrain['Text'].values # Use appropriate column names\n",
    "Zage_labels_train = dftrain['ZAge'].values\n",
    "Input_ids_train, Attention_masks_train = toke_and_enc(All_text_train)\n",
    "Zage_labels_train = torch.tensor(Zage_labels_train)\n",
    "Train_dataset = TensorDataset(Input_ids_train, Attention_masks_train, Zage_labels_train)\n",
    "model_train = train_model(Train_dataset)\n",
    "# Save model (optional)\n",
    "# model_train.save_pretrained() # Uncomment to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training result\n",
      "here\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . DONE.\n",
      "  |   0   1   2   3   4   5   6   7   8   9 |\n",
      "--+-----------------------------------------+\n",
      "0 |<121>  .   .   .   1   .   .   .   .   . |\n",
      "1 |   . <10>  3   .   .   .   .   .   .   . |\n",
      "2 |   1   . <78>  .   .   .   .   .   .   . |\n",
      "3 |   .   1   2  <.>  .   .   .   2   2   . |\n",
      "4 |   .   .   .   . <35>  .   .   .   4   1 |\n",
      "5 |   .   .  13   .   .  <1>  .   .   1   . |\n",
      "6 |   .   .   1   .   .   .  <.>  .   .   . |\n",
      "7 |   2   .   1   .   1   .   .<182>  .   1 |\n",
      "8 |   .   .   .   .   .   .   .   1 <72>  1 |\n",
      "9 |   .   .   .   .   .   .   .   .   1 <20>|\n",
      "--+-----------------------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98       122\n",
      "           1       0.91      0.77      0.83        13\n",
      "           2       0.80      0.99      0.88        79\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.95      0.88      0.91        40\n",
      "           5       1.00      0.07      0.12        15\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.98      0.97      0.98       187\n",
      "           8       0.90      0.97      0.94        74\n",
      "           9       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.93       559\n",
      "   macro avg       0.74      0.66      0.66       559\n",
      "weighted avg       0.92      0.93      0.91       559\n",
      "\n",
      "testing result\n",
      "here\n",
      ". . . . . . . . . DONE.\n",
      "  |  0  1  2  3  4  5  7  8  9 |\n",
      "--+----------------------------+\n",
      "0 |<17> .  .  .  .  .  9  1  . |\n",
      "1 |  1 <1> .  .  .  .  .  1  . |\n",
      "2 |  .  .<21> .  .  .  2  1  . |\n",
      "3 |  .  .  . <.> .  .  4  1  . |\n",
      "4 |  .  .  1  . <4> .  2  .  4 |\n",
      "5 |  .  .  .  .  . <.> 3  .  . |\n",
      "7 |  3  .  2  .  .  .<27> 7  . |\n",
      "8 |  .  .  .  .  1  .  9<13> . |\n",
      "9 |  .  .  .  .  3  .  .  . <2>|\n",
      "--+----------------------------+\n",
      "(row = reference; col = test)\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.63      0.71        27\n",
      "           1       1.00      0.33      0.50         3\n",
      "           2       0.88      0.88      0.88        24\n",
      "           3       0.00      0.00      0.00         5\n",
      "           4       0.50      0.36      0.42        11\n",
      "           5       0.00      0.00      0.00         3\n",
      "           7       0.48      0.69      0.57        39\n",
      "           8       0.54      0.57      0.55        23\n",
      "           9       0.33      0.40      0.36         5\n",
      "\n",
      "    accuracy                           0.61       140\n",
      "   macro avg       0.50      0.43      0.44       140\n",
      "weighted avg       0.60      0.61      0.59       140\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the model on the training data set to collect stat and output\n",
    "print('training result')\n",
    "trainpred, trainactual = test_model(Train_dataset, model_train)\n",
    "train_pred, train_actual  = calculate_stat(trainpred, trainactual)\n",
    "dftrain['Mpred'] = train_pred\n",
    "dftrain['Mactual'] = train_actual\n",
    "dftrain.to_csv('outtrain.csv', encoding='utf-8')\n",
    "\n",
    "# Run the model on the test data set to collect stat and output\n",
    "print('testing result')\n",
    "All_text_test = dftest['Text'].values\n",
    "Zage_labels_test = dftest['ZAge'].values\n",
    "Input_ids_test, Attention_masks_test = toke_and_enc(All_text_test)\n",
    "Zage_labels_test = torch.tensor(Zage_labels_test)\n",
    "Test_dataset = TensorDataset(Input_ids_test, Attention_masks_test, Zage_labels_test)\n",
    "testpred, testactual = test_model(Test_dataset, model_train)\n",
    "test_pred, test_actual  = calculate_stat(testpred, testactual)\n",
    "dftest['Mpred'] = test_pred\n",
    "dftest['Mactual'] = test_actual\n",
    "dftest.to_csv('outtest.csv', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
